---
layout:     post
title:      经典CTR模型(1)---GBDT+LR
subtitle:   Practical Lessons from Predicting Clicks on Ads at Facebook
date:       2020-01-01
author:     weber
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - recommender systems
    - CTR
---
论文：[Practical Lessons from Predicting Clicks on Ads at Facebook](papers3://publication/doi/10.1145/2648584.2648589)，KDD 2014，Facebook



# 1. 论文背景

CTR预估发展初期，使用最多的方法就是LR。

> LR优点：
>
> 1. 容易并行化，可以轻松处理上亿条数据；
> 2. 使用sigmoid函数将结果映射到了 (0,1)；
>
> LR缺点：
>
> 1. 学习能力有限，需要大量人工特征工程；

GBDT可以对原始特征进行特征划分和特征组合，可以使用GBDT来构造组合特征。

# 2. 融合方案

GBDT+LR的方案如图所示。

![](https://tva1.sinaimg.cn/large/00831rSTly1gd3jr1p5vnj30uk0oc0x3.jpg)

输入：样本 x 的原始特征

GBDT：图中有两棵树，经过两棵树后，x样本的原始特征分别落到两颗树的叶子节点上，每个叶子节点对应LR一维特征，那么通过遍历树，就得到了该样本对应的所有LR特征。构造的新特征向量是取值0/1。举例来说：上图有两棵树，左树有三个叶子节点，右树有两个叶子节点，最终的特征即为五维的向量。对于输入x，假设他落在左树第一个节点，编码[1,0,0]，落在右树第二个节点则编码[0,1]，所以整体的编码为[1,0,0,0,1]

LR：这类编码作为特征，输入到LR中进行分类

输出：0-1之间的预测值

# 3. 优缺点

优点：

1. 特征工程自动化，通过GBDT自动探索特征组合；

缺点：

1. 是二阶段的，非端到端模型；
2. CTR涉及大量高维稀疏特征，树模型不适合处理（因此会将dense特征或低维sparse特征给GBDT，高维sparse特征在LR阶段训练）；
3. GBDT模型复杂，无法online learning，模型对数据敏感度滞后；

# 4. 思考

> 1. RF + LR 相较于 GBDT + LR，有哪些优缺点？

优点是可以并行；缺点是实验效果比GBDT差，RF的每棵树学习到的特征组合相差可能不大，GBDT优先学习重要的特征，后面的树是在前面的树的基础上进一步拟合残差，互补的可能性更大。

> 2. GBDT + LR 能否有效处理大量ID类特征？

不能，树模型非常难以处理大量属性分布不均衡的特征。可以考虑使用wide&deep的思想。

> 3. GBDT + LR 一定比单独的GBDT，LR好吗？

一般是。但如果GBDT的叶子结点太少，加上LR可能反而更差。