---
layout:     post
title:      经典CTR模型(5)---DeepCross
subtitle:   Deep Crossing Web-Scale Modeling without Manually Crafted Combinatorial Features
date:       2020-01-06
author:     weber
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - recommender systems
    - CTR
---

论文：[Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features](http://xueshu.baidu.com/usercenter/paper/show?paperid=a68eb0dd4fe70e1f78de7007246d885f&site=xueshu_se)，KDD，2016，微软

# 1. 背景介绍

Deep&Cross其实也属于双路并行的模型结构，只不过提出了一种新的模型叫做Cross Net来替代DeepFM中的FM部分。DNN本身虽然具备高阶交叉特征的学习能力，但其对于特征交叉的学习是隐式的、高度非线性的一种方式，因此作者提出了Cross Net，它可以显式地进行特征的高阶交叉，CrossNet相比于DNN的优势主要在于：

- 可以显式的学习有限阶的特征交叉；
- 计算时间复杂度比DNN更低；

# 2. DCN结构

![image-20200323141158509](https://tva1.sinaimg.cn/large/00831rSTly1gd3u0fcefrj30u20s27jv.jpg)

由图可以看到，分为嵌入层，Cross Net + Deep Net ，组合输出层 三部分，重点说明第二部分。

## 2.1 Cross Network

交叉网络由交叉层组成，每个层具有以下公式：
$$
x_{l+1} = x_0 x_l^Tw_l + b_l + x_l = f(x_l,w_l,b_l)+x_l
$$

CrossNet的主要思想是显式地计算内积来进行层与层之间的信息交叉；另外，CrossNet在设计上还借鉴了残差网络的思想，使得每一层的输出结果能够包含原始的输入信息。一个交叉层的可视化如图所示:

![image-20200323143547698](https://tva1.sinaimg.cn/large/00831rSTgy1gd3up7juj2j31s00q019y.jpg)


>**bit-wise VS vector-wise**
>假设隐向量的维度为3维，如果两个特征 (对应的向量分别为(a1,b1,c1)和(a2,b2,c2)的话）在进行交互时，交互的形式类似于f(w1 * a1 * a2, w2 * b1 * b2 , w3 * c1 * c2)的话，此时我们认为特征交互是发生在**元素级（bit-wise）**上。如果特征交互形式类似于 f(w * (a1 * a2 ,b1 * b2,c1 * c2))的话，那么我们认为特征交互是发生在**特征向量级（vector-wise）**。
>
>这里我们可以看到，CrossNetwork的特征交互是 **bit-wise** 的。
>
>![image-20200323152430812](https://tva1.sinaimg.cn/large/00831rSTly1gd3w3vxpo9j31qi0miaq3.jpg)
>
>---
>**explicitly VS implicitly**
>显式的特征交互和隐式的特征交互。以两个特征为例xi和xj，在经过一系列变换后，我们可以表示成 wij * (xi * xj)的形式，就可以认为是显式特征交互，否则的话，是隐式的特征交互。
>
>这里可以看到，CrossNetwork 的特征交互是 **explicitly** 的。

# 3. 优缺点

优点：

1. 显式的高阶特征交叉的能力；
2. 结合了ResNet的思想，将原始信息再CrossNet中进行传递；

缺点：

1. 交叉时候是bit-wise；
2. CrossNet最终的输出有一定的局限性，CrossNet的每一层输出都是输入向量的标量倍，这种形式在一定程度上限制了模型的表达能力

