---
layout:     post
title:      2020春招-小米面试-面经
subtitle:   小米面试经验
date:       2020-04-08
author:     weber
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 面经
---

公司：小米

岗位：推荐算法实习生

# 1. 一面

- 介绍项目，比赛，论文

- DeepFM与WDL的区别

- DIN中注意力是怎么设计的，好处在哪

- 手推xgboost的gain

- 手推交叉熵

- lightGBM与XGboost的区别

- XGboost的特征重要性是如何算的，怎么算

- LightGBM要调哪些参数

- ResNet是仅仅为了拟合残差吗？有什么别的trick吗

- 三道算法题
	1. LCS - leetcode 1143
  2. 删除链表的结点（ 要求时间复杂度为O(1)） -  leetcode 面试题 18
  3. 搜索二维矩阵 - leetcode 240

# 2. 二面

二面面试官迟到了半个小时，面试态度也很一般，给人感觉非常不好。但从问问题的细节和深度来看，懂得很多，确实是有真才实学的。

- dropout=0.8，相当于训练集只用0.8，而测试集会用1（全部节点去预测），会有什么问题？
- BN与LN的区别，LN的方差需要保证什么？
- WDL中，wide部分与deep部分都是如何优化的，为什么不使用统一的优化器
- bp为什么不使用二阶导使用一阶导，为什么xgboost可以使用二阶导
- gbdt拟合残差为什么有效？obj函数是什么？
- DIN中的attention，为什么这样设计，效果如何？问的非常细。
- DIEN中的GRU是做什么的，是什么在做attention，auxilary loss计算的是什么
- DSIN中的每个用户的ssession的个数不一致是如何处理的
- GRU和LSTM为什么可以解决梯度消失
- LR为什么是Sigmoid函数，是否可以用其他函数代替，从三个方面来解释
- 算法题
  1. 输入一个pair对数组，int \[n]\[2]，pair对中的每个值表示用户1与用户2是朋友，求这n个用户有多少朋友圈

