---
layout:     post
title:      推荐系统的多目标优化(3)-DUPN
subtitle:   Deep User Perception Network
date:       2020-05-03
author:     weber
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags:
    - 多目标
    - 论文笔记
    - recommender systems
---

论文：[Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks](https://arxiv.org/pdf/1805.10727.pdf)，KDD，2018，阿里

目录：
[toc]
# 1. 提出背景

**深度用户感知网络 (Deep User Perception Network, DUPN)** 是与ESMM同期的多目标论文，二者的思想有很多共同点。DUPN阐述了多任务学习的意义：

1. **embedding词表共享，节省资源**。相较于多个单任务，网络结构更小，在线CPU使用率更低，存储资源更少。
2. 更通用的embedding表示，方便迁移。学习到的user，item向量，可以方便的迁移到其他业务。

# 2. DUPN模型

![image-20200428102054261](https://tva1.sinaimg.cn/large/007S8ZIlly1ge99n2siraj318p0u0qba.jpg)

深度用户感知网络 (Deep User Perception Network, DUPN) 结构如图，分为五层：行为序列层，Embedding层，LSTM层，Attention层，多任务层。

## 2.1 Behavior Sequence层

行为序列层是模型的输入。行为序列 $ x = \{x_1,x_2,...,x_N\}$中每个行为 $x_i$ 由物品特征和上下文特征两部分组成。

- 物品特征：物品ID，商铺ID，品牌，类别，标签等
- 上下文特征：行为类型（点击购买/收藏/购物车），行为场景（搜索/推荐/广告），行为时间（上午/晚上，周中/周末）等

每个行为 $x_i$ 最终可以转为 multi-hot 向量。

> 本文实验中，把用户行为序列的长度设为100，实际应考虑场景下自己用户行为序列长度的大小。

## 2.2 Embedding层

Embedding层根据不同特征的词表大小，分配了不同的embedding维度。物品ID,商铺ID,品牌,类别,标签的词表量级分别为：1G,1M,10M,1M,100k。对应的emb维度为：32,24,24,16,28。最终每个行为可以编码为172维向量，根据商品和行为上下文分开，分别表示为 $e_i$ 和 $p_i$。

![image-20200428103604064](https://tva1.sinaimg.cn/large/007S8ZIlly1ge9a2um6noj31hc0euq6f.jpg)

> Multi-hot的特征(比如标签)，商品可能会有多个标签，应该会通过pooling操作进行转换。

## 2.3 LSTM层

得到了每一个行为的Embedding表示之后，首先通过一个改造的LSTM层，把行为的序列信息考虑进来。

因为行为向量 $p_i$ 不能反映物品特征，只能反映行为的重要程度，所以用来做为 LSTM 的 gate 的输入。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9amy4zfcj318q0py0yk.jpg" alt="image-20200428105522565" style="zoom:33%;" />

LSTM的表示式为：

<img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ge9awbmzfej31400estb4.jpg" alt="image-20200428110422448" style="zoom:33%;" />

输出：建模的行为序列隐向量（128维）。

## 2.4 Attention层

与DIN，DIEN类似，对用户行为序列中的注意力进行建模。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9azzr5kjj31c00q8q6s.jpg" alt="image-20200428110738553" style="zoom:50%;" />

输入：行为序列上下文特征 $p_i$ (48维)，行为序列隐向量特征 $h_i$ (128维)，用户特征 $u$ (128维)，query特征 

输出：注意力 $a_t$ 为标量，加权后的特征表示 $rep_s$ (128维)

表达式：

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9b5dmip9j30s80ast9x.jpg" alt="image-20200428111304063" style="zoom:33%;" />

> query特征：作者的场景是由检索的，query指的是user输入的查询关键字，可以通过word2vec等方法，将关键字转为emb。如果是无检索的推荐场景，与DIN类似，可以考虑使用当前算ctr的item的emb表示。

经过Attention层，将行为序列得到的128维特征表示和用户特征128维进行拼接，得到一个用户的256维向量。

## 2.5 Multi-Task层

作者将共享的embedding用于5个子任务：CTR，L2R(learning to rank)，PPP(Price Preference Prediction)，FIFP(Fashion Icon Following Prediction)，Shop Preference Prediction (SPP)。

> 每个任务基本上都是 Emb + MLP 的结构。作者实验时再每层全连接后面加了 Dropout (0.8) 来防止过拟合。ESM2也同样使用了Dropout来防止过拟合。
>
> 除了Dropout，作者还使用了L2正则。并在视频里提及了 BN 也可以提升效果。
>
> BN使用时需注意：训练样本中BN记住的离线均值和方差和在线数据中一定要保持一致。举例来说，在训练样本中会做各种过滤和采样，例如把点击样本采样，那么这样会导致某些维度的均值会远远高于实际线上的均值，虽然在测试集上的AUC也能提升，但这对在线效果非常不利。

### 点击率预测 CTR
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9bqi0wf1j30uu0mutag.jpg" alt="image-20200428111304063" style="zoom:33%;" />

输入：刚才得到的user rep(256维) $rep_i$，item emb(128维) $e_i $

输出：预测的ctr概率 $score(rep_i,e_i;\alpha)$

损失：$L_{ctr}= -\frac{1}{N}\sum_{i=1}^N[y_i\log score(rep_i,e_i;\alpha)+(1-y_i)\log (1- score(rep_i,e_i;\alpha))]$

> 思考：之前构建user时使用的item是124维，这里可以考虑使用同一个item表示。

### 排序评分学习 L2R
<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9bqv89wmj30um0o6jt7.jpg" alt="image-20200428111304063" style="zoom:33%;" />

目标：对商品的26个排序特征进行权重学习，得到Rank分排序，来最大化CVR

输入：刚才得到的user rep(256维) $rep_i$，rank features(26维) $r_i$

>  rank features：(商品的)销售量，用户评分，预测的CTR，价格偏好等，共26维。

输出：排序特征的评分 $weight(rep_i;\theta)^T r_i$

损失：$L_{L2R}=\sum_i n_i \log (1+exp(-y_iweight(rep_i;\theta)^T r_i))$，$n_i$为不同类型(点击/购买)的样本的权重，由于标签是\{-1,1\}，所以交叉熵损失形式变化如式。

### 购买力预测 PPP

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9br75vrej30k60n4jsc.jpg" alt="image-20200428111304063" style="zoom:33%;" />

将用户的购买力分为7档，根据用户特征，来预测用户的购买力属于哪一档。

### 达人偏好预测 FIFP

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9brn5ii7j30v60oegnc.jpg" alt="image-20200428111304063" style="zoom:33%;" />

目标：预测用户是否会follow某一些达人。

输入：刚才得到的user rep(256维) $rep_i$，达人特征(128维) $f_i$

### 店铺偏好预测 SPP

目标：预测用户对于店铺的偏好。

输入：刚才得到的user rep(256维) $rep_i$，店铺特征(64维) $s_i$

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9h9uhqzpj30ue0q6tah.jpg" alt="image-20200428144450391" style="zoom: 33%;" />

## 2.6 损失函数

# 3. 实验结果

## 3.1 实验数据

数据是淘宝真实数据

离线： train 10天日志；eval 下1天日志

在线：每天的10%做 A/Btest

训练时间：96个参数服务器，2000worker，每个服务器15个核CPU，训练需要4天

## 3.2 实验结果

### 多任务学习vs单任务学习

![image-20200428150526965](https://tva1.sinaimg.cn/large/007S8ZIlly1ge9hv5fjzoj31n80pmqdg.jpg)

文章比较了5个任务，我以前两个子任务的结果来截图说明。可以看到，在测试集上，多任务学习模型效果更好，模型的泛化能力得到了提升。

### DUPN vs 其他

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9hz2f0shj314y0moq7g.jpg" alt="image-20200428150913674" style="zoom:50%;" />

- DUPN-nobp：不使用behavior property；
- DUPN-bplstm：只在lstm部分使用behavior property；
- DUPN-bpatt：只在attention部分使用behavior property；
- DUPN-all：前文的DUPN；
- DUPN-w2v：不再端到端emb，把用户行为序列当作sentence，对item emb使用word2vec进行预训练。

### 模型迁移能力

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9i46d32fj31ei0rydmt.jpg" alt="image-20200428151403416" style="zoom: 33%;" />

在训练完包含前4个任务的多任务模型之后，通过SPP实验来验证一下模型的迁移能力。有几种方法应用于第5个任务上：

- Re-training with Single task：使用DUPN的网络结构单独训练这一个新任务；
- Re-training with All tasks：使用DUPN的网络结构重新训练5个任务；
- Representation Transfer：将学习到的用户表示以及店铺属性作为输入，训练一个简单的网络，这里用户表示不会被更新；
- Network Fine Tuning：将学习到的用户表示以及店铺属性作为输入，训练一个简单的网络，这里用户表示会随着网络训练而Fine Tuning；

AUC变化如图，说明之前的网络已经达到了较好的训练效果，进行一些微调后便可以很快得到最终结果。

### 线上A/B test

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ge9iayfx22j315a0pi780.jpg" alt="image-20200428152039082" style="zoom:50%;" />

# 4. 思考

DUPN验证了多任务学习的有效性，为推荐系统的多任务学习提供了实践思路，同时介绍了很多trick。

尤其是共享的user emb建模方案，值得学习和尝试。

