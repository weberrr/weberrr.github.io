# LTR出现背景
信息检索系统已经发展了几十年，人们才开始使用机器学习对搜索结果进行排序，原因有二：
- **传统检索所需要考虑的因素不多。**一般只考虑搜索内容与文档的相关性、逆文档频率、文档长度等几个因子，人工进行公示拟合完全可行。但随着搜索引擎的发展，所需要考虑的因素增多，比如网页的pageRank值、查询和文档匹配的单词个数、网页URL链接地址长度等都对网页排名产生影响，**机器学习正好适合采用很多特征来进行公式拟合。**
- **有监督机器学习需要大量数据。**搜索引擎可以提供大量的用户行为数据，并且实际经验表明，使用这种点击数据来训练机器学习系统确实是可行的。
# LTR基本框架
LTR本质还是机器学习。只是目标不仅仅是简单的分类或者回归了，最主要的是产出文档的排序结果，它通常的工作框架如下:
![ltr_framework](https://upload-images.jianshu.io/upload_images/6802002-2ae7ef59ad14ceae.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/840)
步骤：**训练数据获取->特征提取->模型训练->测试数据预测->效果评估。**
# 数据获取
##### 1.人工标注
- 单点标注 ： 对于每个查询文档打上绝对标签：相关/不相关；好/中/差。O(n)
- 两两标注 ： 对一个查询Query,要标注文档d1比文档d2是否更加相关。O(n^2)
- 列表标注 ： 对于一个查询Query，将人工理想的排序整个标好。
##### 2.搜索日志
##### 3.公共数据集
- LETOR, http://research.microsoft.com/en-us/um/beijing/projects/letor/
- Microsoft Learning to Rank Dataset, http://research.microsoft.com/en-us/projects/mslr/
- Yahoo Learning to Rank Challenge, http://webscope.sandbox.yahoo.com/
# 特征提取
搜索引擎会使用一系列特征来决定结果的排序。一个特征称之为一个“feature”。分3类：
- Doc本身的特征：Pagerank、内容丰富度、是否是spam、质量值、CTR等
- Query-Doc的特征：Query-Doc的相关性、Query在文档中出现的次数，査询词的Proximity值（即在文档中多大的窗口内可以出现所有査询词）等。当然，有些Query-Doc的特征不是显式的，而是有Semantic的，即虽然Query在文档中没有出现，但是语义上是有关系的。
- Query的特征：Query 在所有Query 中的出现次数、比率等
# 模型训练方法
##### 单文档方法（PointWise）
处理对象是一篇文档，将文档转换为特征向量后，机器学习系统用从文档中学习到的分类或回归函数对文档进行打分，打分排序结果就是搜索结果。下图是人工标注的训练集合：
在这个例子中，我们对于每个文档采用了3个特征： 査询与文档的Cosme相似性分值、査询词的Proximity值及页面的PageRank数值，而相关性判断是二元的，即要么相关要么不相关。
例子中提供了5个训练实例，每个训练实例分别标出来其对应的查询，3个特征的得分情况及相关性判断。对于机器学习系统来说，根据训练数据，需要如下的线性打分函数：

**Score(Q, D) = a * CS + b * PM + c * PR + d**
![单文档](https://upload-images.jianshu.io/upload_images/6802002-77d730b915da761b.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
如果得分大于设定阈值，则可以认为是相关的， 如果小于设定阈值则可以认为不相关。通过训练实例，可以获得最优的a、b、c、d参数组合，当这些参数确定后，机器学习系统就算学习完毕。之后即可利用这个打分函数进行相关性判断。

**特点：**速度快，复杂度低；但没有考虑到文档之间的相对关系，效果一般。

##### 文档对方法（PairWise）
Pairwise主要是将排序问题转为了文档对顺序的判断。
如图，对于查询Q1，进行人工标注之后，Doc2=5的分数最高，其次是Doc3为4分，最差的是Doc1为3分，将此转为相对关系之后有:Doc2>Doc1、Doc2>Doc3、Doc3>Doc1，所以排序问题可以很自然的转为任意两个文档关系的判断，而任意两个文档顺序的判断就称为了一个很熟悉的分类问题。
![文档对](https://upload-images.jianshu.io/upload_images/6802002-6000c28bd9c06f6f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/640)
**如何将排序问题转化为机器学习能够学习的分类问题呢？**
参考文献[Learning to Rank之Ranking SVM 简介](http://www.cnblogs.com/kemaswill/p/3241963.html)给出了一个很好的例子解释这个问题：给定查询q, 文档d1>d2>d3(亦即文档d1比文档d2相关, 文档d2比文档d3相关, x1, x2, x3分别是d1, d2, d3的特征)。为了使用机器学习的方法进行排序，我们将排序转化为一个分类问题。我们定义新的训练样本, 令x1-x2, x1-x3, x2-x3为正样本,令x2-x1, x3-x1, x3-x2为负样本, 然后训练一个二分类器(支持向量机)来对这些新的训练样本进行分类，如下图所示:

![](https://upload-images.jianshu.io/upload_images/6802002-1c8a2778150c12a7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
左图中每个椭圆代表一个查询, 椭圆内的点代表那些要计算和该查询的相关度的文档, 三角代表很相关, 圆圈代表一般相关, 叉号代表不相关。我们把左图中的单个的文档转换成右图中的文档对(di, dj), 实心方块代表正样本, 亦即di>dj, 空心方块代表负样本, 亦即di < dj。将【排序问题转化为分类问题】之后, 我们就可以使用常用的机器学习方法解决该问题。

**PairWise常用算法**
- Ranking SVM (ICANN 1999)
- RankBoost (JMLR 2003)
- IRSVM (SIGIR 2006)
- LambdaRank (NIPS 2006)
- **LambdaMART** (inf.retr 2010)​​​​​​​

**问题：**
- 只考虑了两个文档的先后顺序，没有考虑文档出现在搜索列表中的位置
- 不同的查询，其相关文档数量差异很大，转换为文档对之后，有的查询可能有几百对文档，有的可能只有几十个，最终对机器学习的效果评价造成困难。
##### 文档列表方法（ListWise）
文档列方法根据K个训练实例训练得到最优的评分函数F，对于一个新的查询，函数F对每一个文档进行打分，之后按照得分顺序高低排序，就是对应的搜索结果。
所以关键问题是：**拿到训练数据，如何才能训练得到最优的打分函数？**

我们知道，对于搜索引擎来说，用户输入査询Q， 搜索引擎返回搜索结果，我们假设搜索结果集合包含A. B 和C 3个文档，搜索引擎要对搜索结果排序，而这3个文档的顺序共有6种排列组合方式:

ABC, ACB, BAG, BCA, CAB和CBA

而每种排列组合都是一种可能的搜索结果排序方法。

对于某个评分函数F来说，对3个搜索结果文档的相关性打分，得到3个不同的相关度得分F(A)、 F(B)和F(C)， 根据这3个得分就可以计算6种排列组合情况各自的概率值。 不同的评分函数，其6种搜索结果排列组合的概率分布是不一样的。

这里介绍一种训练方法，它是基于搜索结果排列组合的概率分布情况来训练的，下图是这种方式训练过程的图解示意。
![](https://upload-images.jianshu.io/upload_images/6802002-675203ad2448ceb0.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

上图展示了一个具体的训练实例，即査询Q1及其对应的3个文档的得分情况，这个得分是由人工打上去的，所以可以看做是标准答案。可以设想存在一个最优的评分函数g，对查询Q1来说，其打分结果是：A文档得6分，B文档得4分，C文档得3分。

我们的任务就是找到一 个函数，使得函数对Q1的搜索结果打分顺序和人工打分顺序尽可能相同。

既然人工打分 (虚拟的函数g) 已知，那么我们可以计算函数g对应的搜索结果排列组合概率分布，其具体分布情况如上图中间的概率分布所示。假设存在两个其他函数h和f，它们的计算方法已知，对应的对3个搜索结果的打分在图上可以看到，由打分结果也可以推出每个函数对应的搜索结果排列组合概率分布，那么h与f哪个与虚拟的最优评分函数g更接近呢？**一般可以用两个分布概率之间的距离远近来度量相似性**，KL距离就是一种衡量概率分布差异大小的计算工具，通过分别计算h与g的差异大小及f与g的差异大小，可以看出f比h更接近的最优函数g，那么在这个函数中，我们应该优先选f作为将来搜索可用的评分函数，训练过程就是在可能的函数中寻找最接近虚拟最优函数g的那个函数作为训练结果，将来作为在搜索时的评分函数。

上述例子只是描述了对于单个训练实例如何通过训练找到最优函数，事实上我们有K个训练实例，虽然如此，其训练过程与上述说明是类似的，可以认为存在一个虚拟的最优评分函数g (实际上是人工打分），训练过程就是在所有训练实例基础上，探寻所有可能的候选函数，从中选择那个KL距离最接近于函数g的，以此作为实际使用的评分函数。 经验结果表明，基于文档列表方法的机器学习排序效果要好于前述两种方法。

**Listwise常用算法**
- AdaRank (SIGIR 2007)
- SVM-MAP (SIGIR 2007)
- SoftRank (LR4IR 2007)
- RankGP (LR4IR 2007)
- **LambdaMART** (inf.retr 2010)（也可以做Listwise）

# 参考链接
[排序学习（Learning to rank）综述](https://blog.csdn.net/anshuai_aw1/article/details/86018105)
[机器学习算法-初识Learning to Rank](https://jiayi797.github.io/2017/08/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95-%E5%88%9D%E8%AF%86Learning-to-Rank/)
